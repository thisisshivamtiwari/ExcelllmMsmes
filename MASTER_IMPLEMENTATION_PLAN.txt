================================================================================
                    EXCELLLM - MASTER IMPLEMENTATION PLAN
                    Excel Parser → Schema Management → Relationships → Visualizations
================================================================================

Last Updated: 2026-01-15
Status: Ready for Implementation
Total Estimated Time: 8-10 weeks

================================================================================
                            TABLE OF CONTENTS
================================================================================

1. PHASE 1: Excel Parser & Data Loading (Week 1-2)
2. PHASE 2: Schema Detection & Type Inference (Week 2-3)
3. PHASE 3: Intelligent Schema Normalization (Week 3-5)
4. PHASE 4: Cross-File Relationship Detection (Week 5-6)
5. PHASE 5: Data Validation & Cleaning (Week 6-7)
6. PHASE 6: Schema Registry & Storage (Week 7)
7. PHASE 7: Visualization System (Week 7-8)
8. PHASE 8: API Integration & Frontend (Week 8-9)
9. PHASE 9: Testing & Documentation (Week 9-10)

================================================================================
                        PHASE 1: EXCEL PARSER & DATA LOADING
                        Estimated Time: 1-2 weeks
================================================================================

FOLDER STRUCTURE:
-----------------
excel_parser/
├── __init__.py
├── excel_loader.py
├── file_validator.py
└── metadata_extractor.py

TODO ITEMS:
-----------
[ ] 1.1 Create excel_parser/ directory structure
[ ] 1.2 Implement excel_loader.py
    [ ] Load .xlsx files (multiple sheets support)
    [ ] Load .csv files
    [ ] Handle large files (>50k rows) with chunking
    [ ] Preserve data types during loading
    [ ] Error handling for corrupted files
    [ ] Progress tracking for large files
    
[ ] 1.3 Implement file_validator.py
    [ ] Validate file format (.xlsx, .csv)
    [ ] Check file size limits
    [ ] Verify file is not corrupted
    [ ] Check encoding (UTF-8, etc.)
    
[ ] 1.4 Implement metadata_extractor.py
    [ ] Extract file metadata (name, size, modified date)
    [ ] Count rows and columns
    [ ] Detect file encoding
    [ ] Extract sheet names (for Excel)
    
[ ] 1.5 Write unit tests
    [ ] Test .xlsx loading
    [ ] Test .csv loading
    [ ] Test error handling
    [ ] Test large file handling
    
[ ] 1.6 Create requirements.txt
    [ ] pandas>=2.0.0
    [ ] openpyxl>=3.1.0
    [ ] python-dateutil>=2.8.0

DELIVERABLES:
-------------
✓ Can load .xlsx and .csv files
✓ Handle multiple sheets per Excel file
✓ Extract file metadata
✓ Error handling for invalid files

DEPENDENCIES:
-------------
None (starting phase)

REFERENCE DOCS:
---------------
- NEXT_PHASE_PLAN.md (Section 1.1)

================================================================================
                    PHASE 2: SCHEMA DETECTION & TYPE INFERENCE
                        Estimated Time: 1 week
================================================================================

FOLDER STRUCTURE:
-----------------
excel_parser/
├── schema_detector.py
└── type_inference.py

TODO ITEMS:
-----------
[ ] 2.1 Implement schema_detector.py
    [ ] Detect all columns in DataFrame
    [ ] Extract column names
    [ ] Get basic statistics (count, unique values, nulls)
    [ ] Identify potential primary keys
    [ ] Detect potential foreign keys
    
[ ] 2.2 Implement type_inference.py
    [ ] Infer column types: date, numeric, categorical, text, id
    [ ] Date detection (multiple formats)
    [ ] Numeric detection (int, float, with commas)
    [ ] Categorical detection (limited unique values)
    [ ] ID detection (high uniqueness, patterns)
    [ ] Text detection (free-form strings)
    
[ ] 2.3 Date format detection
    [ ] Detect common date formats
    [ ] Handle mixed date formats
    [ ] Parse dates correctly
    
[ ] 2.4 Write unit tests
    [ ] Test type inference accuracy
    [ ] Test date format detection
    [ ] Test edge cases (empty columns, all nulls)

DELIVERABLES:
-------------
✓ Can detect all columns in a file
✓ Can infer column types accurately (>90%)
✓ Can detect date columns and formats
✓ Can identify key columns (primary/foreign keys)

DEPENDENCIES:
-------------
Phase 1 (Excel Parser)

REFERENCE DOCS:
---------------
- NEXT_PHASE_PLAN.md (Section 1.2)

================================================================================
                PHASE 3: INTELLIGENT SCHEMA NORMALIZATION
                        Estimated Time: 2 weeks
================================================================================

FOLDER STRUCTURE:
-----------------
schema_intelligence/
├── __init__.py
├── semantic_matcher.py
├── fuzzy_matcher.py
├── llm_column_analyzer.py
├── context_analyzer.py
├── confidence_scorer.py
├── pattern_learner.py
└── feedback_handler.py

excel_parser/
└── schema_normalizer.py (orchestrator)

TODO ITEMS:
-----------
[ ] 3.1 Create schema_intelligence/ directory structure

[ ] 3.2 Implement semantic_matcher.py
    [ ] Initialize SentenceTransformer model (all-MiniLM-L6-v2)
    [ ] Build canonical column embeddings
    [ ] Find similar columns using cosine similarity
    [ ] Consider context (table name, other columns)
    [ ] Return top-k matches with scores
    
[ ] 3.3 Implement fuzzy_matcher.py
    [ ] Use rapidfuzz for string matching
    [ ] Normalize strings (lowercase, remove special chars)
    [ ] Calculate edit distance
    [ ] Handle abbreviations and typos
    [ ] Return matches with similarity scores
    
[ ] 3.4 Implement llm_column_analyzer.py
    [ ] Initialize Groq client (Llama 4 Maverick)
    [ ] Build analysis prompt template
    [ ] Analyze column semantics (name + sample data)
    [ ] Return canonical mapping suggestion with reasoning
    [ ] Batch analysis for efficiency
    
[ ] 3.5 Implement context_analyzer.py
    [ ] Infer domain from table name (production/quality/maintenance/inventory)
    [ ] Analyze column co-occurrence patterns
    [ ] Analyze data patterns (formats, distributions)
    [ ] Use context to improve matching
    
[ ] 3.6 Implement confidence_scorer.py
    [ ] Aggregate scores from all strategies
    [ ] Weight different strategies (semantic=0.35, fuzzy=0.20, LLM=0.30, context=0.15)
    [ ] Calculate confidence levels (high/medium/low)
    [ ] Determine if user confirmation needed
    
[ ] 3.7 Implement pattern_learner.py
    [ ] Store successful mappings
    [ ] Extract normalization patterns
    [ ] Learn suffix patterns (_Name → "")
    [ ] Learn prefix patterns (Prod → product)
    [ ] Update learned patterns over time
    
[ ] 3.8 Implement feedback_handler.py
    [ ] Record user corrections
    [ ] Apply corrections to schema registry
    [ ] Update pattern learner
    [ ] Retrain embeddings if needed
    [ ] Track accuracy metrics
    
[ ] 3.9 Implement schema_normalizer.py (orchestrator)
    [ ] Integrate all matching strategies
    [ ] Run strategies in parallel
    [ ] Aggregate results with confidence scoring
    [ ] Handle fallback when confidence is low
    [ ] Learn from successful mappings
    
[ ] 3.10 Write unit tests
    [ ] Test each matching strategy independently
    [ ] Test confidence scoring
    [ ] Test pattern learning
    [ ] Test feedback handling
    
[ ] 3.11 Create requirements.txt
    [ ] sentence-transformers>=2.2.0
    [ ] rapidfuzz>=3.0.0
    [ ] python-Levenshtein>=0.21.0
    [ ] langchain>=0.1.0
    [ ] langchain-groq>=0.1.0
    [ ] scikit-learn>=1.3.0

DELIVERABLES:
-------------
✓ Can normalize column names intelligently
✓ Multi-strategy matching (semantic, fuzzy, LLM, context)
✓ Confidence scoring for all mappings
✓ Pattern learning from user feedback
✓ >85% accuracy on test data

DEPENDENCIES:
-------------
Phase 1 (Excel Parser)
Phase 2 (Schema Detection)

REFERENCE DOCS:
---------------
- FOOLPROOF_SCHEMA_PLAN.md (Complete guide)

================================================================================
                PHASE 4: CROSS-FILE RELATIONSHIP DETECTION
                        Estimated Time: 1-2 weeks
================================================================================

FOLDER STRUCTURE:
-----------------
schema_registry/
├── column_matcher.py
├── data_validator.py
├── relationship_graph.py
├── join_path_finder.py
└── relationship_detector.py (orchestrator)

TODO ITEMS:
-----------
[ ] 4.1 Create schema_registry/ directory structure

[ ] 4.2 Implement column_matcher.py
    [ ] Match columns across different files
    [ ] Use semantic matching (reuse from Phase 3)
    [ ] Use fuzzy matching (reuse from Phase 3)
    [ ] Use LLM analysis (reuse from Phase 3)
    [ ] Calculate data overlap (Jaccard similarity)
    [ ] Return matches with confidence scores
    
[ ] 4.3 Implement data_validator.py
    [ ] Validate foreign key relationships
    [ ] Check if child values exist in parent
    [ ] Validate temporal relationships (date overlap)
    [ ] Calculate overlap ratios
    [ ] Determine relationship strength (strong/medium/weak)
    
[ ] 4.4 Implement relationship_graph.py
    [ ] Initialize NetworkX graph
    [ ] Add nodes (file, column pairs)
    [ ] Add edges (relationships with metadata)
    [ ] Find join paths between tables
    [ ] Get related tables for a given table
    
[ ] 4.5 Implement join_path_finder.py
    [ ] Find shortest path between two tables
    [ ] Find all possible join paths
    [ ] Optimize join order
    [ ] Suggest join strategy for multiple tables
    [ ] Estimate result size
    
[ ] 4.6 Implement relationship_detector.py (orchestrator)
    [ ] Detect all relationships across all files
    [ ] Run column matching for all file pairs
    [ ] Validate relationships with data
    [ ] Build relationship graph
    [ ] Generate relationship statistics
    
[ ] 4.7 Write unit tests
    [ ] Test column matching across files
    [ ] Test relationship validation
    [ ] Test graph building
    [ ] Test join path finding
    
[ ] 4.8 Create requirements.txt
    [ ] networkx>=3.0.0

DELIVERABLES:
-------------
✓ Can detect relationships between files
✓ Can validate relationships with data overlap
✓ Can build relationship graph
✓ Can find join paths between tables
✓ >90% relationship detection accuracy

DEPENDENCIES:
-------------
Phase 1 (Excel Parser)
Phase 2 (Schema Detection)
Phase 3 (Schema Normalization)

REFERENCE DOCS:
---------------
- CROSS_FILE_RELATIONSHIPS.md (Complete guide)

================================================================================
                    PHASE 5: DATA VALIDATION & CLEANING
                        Estimated Time: 1 week
================================================================================

FOLDER STRUCTURE:
-----------------
excel_parser/
└── data_cleaner.py

TODO ITEMS:
-----------
[ ] 5.1 Implement data_cleaner.py
    [ ] Handle missing values (drop, fill, forward-fill strategies)
    [ ] Standardize date formats (convert to ISO: YYYY-MM-DD)
    [ ] Coerce numeric columns (handle strings like "1,234")
    [ ] Remove empty rows/columns
    [ ] Flag and log anomalies
    [ ] Handle duplicate rows
    
[ ] 5.2 Date standardization
    [ ] Convert all dates to ISO format
    [ ] Handle timezone information
    [ ] Preserve time information if present
    
[ ] 5.3 Numeric coercion
    [ ] Remove commas from numbers
    [ ] Handle currency symbols
    [ ] Convert strings to numeric types
    [ ] Handle percentage values
    
[ ] 5.4 Anomaly detection
    [ ] Detect outliers in numeric columns
    [ ] Flag invalid dates
    [ ] Flag impossible values (negative quantities, etc.)
    [ ] Log all anomalies
    
[ ] 5.5 Write unit tests
    [ ] Test missing value handling
    [ ] Test date standardization
    [ ] Test numeric coercion
    [ ] Test anomaly detection

DELIVERABLES:
-------------
✓ Can clean data (missing values, dates, numerics)
✓ Can standardize date formats
✓ Can detect and log anomalies
✓ Cleaned data ready for analysis

DEPENDENCIES:
-------------
Phase 1 (Excel Parser)
Phase 2 (Schema Detection)

REFERENCE DOCS:
---------------
- NEXT_PHASE_PLAN.md (Section 1.4)

================================================================================
                    PHASE 6: SCHEMA REGISTRY & STORAGE
                        Estimated Time: 1 week
================================================================================

FOLDER STRUCTURE:
-----------------
schema_registry/
├── registry.py
├── learning_store.py
└── kpi_mapper.py

TODO ITEMS:
-----------
[ ] 6.1 Implement registry.py
    [ ] Store normalized schemas for all files
    [ ] Fast lookup by column name, table name
    [ ] Track file metadata (path, upload date, row count)
    [ ] Export/import schema as JSON
    [ ] Search schemas by semantic meaning
    
[ ] 6.2 Implement learning_store.py
    [ ] Store learned normalization patterns
    [ ] Store mapping history
    [ ] Store user feedback
    [ ] Calculate accuracy metrics
    [ ] Export learning data
    
[ ] 6.3 Implement kpi_mapper.py
    [ ] Map KPIs to required columns
    [ ] Validate KPI requirements against schemas
    [ ] Suggest column mappings for KPIs
    [ ] Store KPI formulas
    
[ ] 6.4 Storage format
    [ ] Design JSON schema for registry
    [ ] Design JSON schema for learning store
    [ ] Implement persistence (file-based or database)
    
[ ] 6.5 Write unit tests
    [ ] Test schema storage and retrieval
    [ ] Test learning store
    [ ] Test KPI mapping

DELIVERABLES:
-------------
✓ Can store and retrieve schemas
✓ Can store learned patterns
✓ Can map KPIs to columns
✓ Persistent storage working

DEPENDENCIES:
-------------
Phase 1-5 (All previous phases)

REFERENCE DOCS:
---------------
- NEXT_PHASE_PLAN.md (Section 1.5, 1.7)

================================================================================
                        PHASE 7: VISUALIZATION SYSTEM
                        Estimated Time: 1-2 weeks
================================================================================

FOLDER STRUCTURE:
-----------------
visualizations/
├── __init__.py
├── generators/
│   ├── __init__.py
│   ├── schema_visualizer.py
│   ├── relationship_visualizer.py
│   └── similarity_calculator.py
└── layouts/
    ├── __init__.py
    ├── force_directed.py
    ├── hierarchical.py
    └── circular.py

TODO ITEMS:
-----------
[ ] 7.1 Create visualizations/ directory structure

[ ] 7.2 Implement similarity_calculator.py
    [ ] Calculate cosine similarity matrix for all columns
    [ ] Use column embeddings from semantic matcher
    [ ] Generate similarity scores
    
[ ] 7.3 Implement force_directed.py
    [ ] Calculate 2D force-directed layout
    [ ] Calculate 3D force-directed layout
    [ ] Optimize layout with iterations
    [ ] Handle large graphs (1000+ nodes)
    
[ ] 7.4 Implement hierarchical.py
    [ ] Calculate hierarchical/tree layout
    [ ] Handle parent-child relationships
    
[ ] 7.5 Implement circular.py
    [ ] Calculate circular layout positions
    
[ ] 7.6 Implement schema_visualizer.py
    [ ] Generate schema overview dashboard data
    [ ] Generate column distribution charts
    [ ] Generate file comparison visualizations
    
[ ] 7.7 Implement relationship_visualizer.py
    [ ] Generate 2D network graph (Plotly)
    [ ] Generate 3D network graph (Plotly)
    [ ] Generate similarity matrix heatmap
    [ ] Generate 3D similarity surface
    [ ] Generate cross-file Sankey diagram
    [ ] Generate cross-file chord diagram
    
[ ] 7.8 Export functionality
    [ ] Export as PNG (high resolution)
    [ ] Export as SVG (vector)
    [ ] Export as HTML (interactive)
    
[ ] 7.9 Write unit tests
    [ ] Test layout calculations
    [ ] Test similarity calculations
    [ ] Test visualization generation
    
[ ] 7.10 Create requirements.txt
    [ ] plotly>=5.17.0
    [ ] networkx>=3.0.0
    [ ] numpy>=1.24.0
    [ ] scipy>=1.11.0
    [ ] matplotlib>=3.7.0
    [ ] kaleido>=0.2.1

DELIVERABLES:
-------------
✓ Can generate 2D/3D network graphs
✓ Can generate similarity matrices (heatmap + 3D surface)
✓ Can generate cross-file relationship diagrams
✓ Can export visualizations (PNG, SVG, HTML)
✓ Beautiful, interactive visualizations

DEPENDENCIES:
-------------
Phase 1-4 (All previous phases, especially Phase 4 for relationships)

REFERENCE DOCS:
---------------
- SCHEMA_VISUALIZATION_PLAN.md (Complete guide)

================================================================================
                    PHASE 8: API INTEGRATION & FRONTEND
                        Estimated Time: 1-2 weeks
================================================================================

FOLDER STRUCTURE:
-----------------
backend/
├── routes/
│   ├── upload.py
│   ├── schema.py
│   ├── relationships.py
│   └── visualizations.py
└── services/
    ├── file_service.py
    ├── schema_service.py
    └── visualization_service.py

frontend/src/components/visualizations/
├── SchemaDashboard.jsx
├── NetworkGraph2D.jsx
├── NetworkGraph3D.jsx
├── SimilarityMatrix.jsx
├── SimilaritySurface.jsx
├── CrossFileGraph.jsx
└── VisualizationControls.jsx

TODO ITEMS:
-----------
[ ] 8.1 Backend API Endpoints
    [ ] POST /api/upload - Upload Excel/CSV files
    [ ] GET /api/schema/{file_id} - Get schema for file
    [ ] GET /api/schema/list - List all schemas
    [ ] POST /api/schema/normalize - Normalize schema
    [ ] GET /api/relationships/detect - Detect relationships
    [ ] GET /api/relationships/{file_id} - Get relationships for file
    [ ] POST /api/relationships/join-path - Find join path
    [ ] GET /api/visualizations/network-graph - Generate network graph
    [ ] GET /api/visualizations/similarity-matrix - Generate similarity matrix
    [ ] GET /api/visualizations/cross-file-graph - Generate cross-file graph
    [ ] POST /api/visualizations/export - Export visualization
    
[ ] 8.2 Backend Services
    [ ] Implement file_service.py (file upload, storage)
    [ ] Implement schema_service.py (schema operations)
    [ ] Implement visualization_service.py (visualization generation)
    
[ ] 8.3 Frontend Components
    [ ] SchemaDashboard.jsx - Main dashboard
    [ ] NetworkGraph2D.jsx - 2D network graph (Plotly.js)
    [ ] NetworkGraph3D.jsx - 3D network graph (Plotly.js)
    [ ] SimilarityMatrix.jsx - Heatmap (Plotly.js)
    [ ] SimilaritySurface.jsx - 3D surface (Plotly.js)
    [ ] CrossFileGraph.jsx - Sankey/Chord (Plotly.js/D3.js)
    [ ] VisualizationControls.jsx - Filters and controls
    
[ ] 8.4 Frontend Integration
    [ ] Add visualization routes to React Router
    [ ] Integrate with existing sidebar navigation
    [ ] Add visualization page to frontend
    [ ] Style visualizations with Tailwind CSS
    
[ ] 8.5 Write integration tests
    [ ] Test file upload → schema detection → normalization
    [ ] Test relationship detection → visualization generation
    [ ] Test API endpoints

DELIVERABLES:
-------------
✓ Complete API for schema management
✓ Complete API for visualizations
✓ Frontend dashboard for visualizations
✓ Interactive visualizations in browser
✓ Export functionality

DEPENDENCIES:
-------------
Phase 1-7 (All previous phases)

REFERENCE DOCS:
---------------
- NEXT_PHASE_PLAN.md (Section 6, 7)
- SCHEMA_VISUALIZATION_PLAN.md (API Endpoints section)

================================================================================
                    PHASE 9: TESTING & DOCUMENTATION
                        Estimated Time: 1 week
================================================================================

TODO ITEMS:
-----------
[ ] 9.1 End-to-End Testing
    [ ] Test complete pipeline: Upload → Normalize → Relationships → Visualize
    [ ] Test with real MSME Excel files
    [ ] Test with edge cases (empty files, malformed data)
    [ ] Performance testing (large files, many files)
    
[ ] 9.2 Accuracy Testing
    [ ] Measure schema normalization accuracy (>85% target)
    [ ] Measure relationship detection accuracy (>90% target)
    [ ] Measure visualization rendering performance (<2s for 1000 nodes)
    
[ ] 9.3 Documentation
    [ ] Write API documentation
    [ ] Write user guide
    [ ] Write developer guide
    [ ] Create example notebooks
    
[ ] 9.4 Code Quality
    [ ] Code review
    [ ] Refactoring if needed
    [ ] Add docstrings
    [ ] Add type hints

DELIVERABLES:
-------------
✓ Comprehensive test coverage
✓ Complete documentation
✓ Production-ready code

DEPENDENCIES:
-------------
Phase 1-8 (All phases)

================================================================================
                            OVERALL DEPENDENCIES
================================================================================

PYTHON PACKAGES:
----------------
pandas>=2.0.0
openpyxl>=3.1.0
python-dateutil>=2.8.0
sentence-transformers>=2.2.0
numpy>=1.24.0
scikit-learn>=1.3.0
rapidfuzz>=3.0.0
python-Levenshtein>=0.21.0
langchain>=0.1.0
langchain-groq>=0.1.0
networkx>=3.0.0
plotly>=5.17.0
scipy>=1.11.0
matplotlib>=3.7.0
kaleido>=0.2.1

FRONTEND PACKAGES:
------------------
plotly.js>=2.26.0
react-plotly.js>=2.6.0
recharts>=2.10.0
d3>=7.8.0
vis-network>=9.1.9

================================================================================
                            IMPLEMENTATION ORDER
================================================================================

CRITICAL PATH:
--------------
Phase 1 → Phase 2 → Phase 3 → Phase 4 → Phase 5 → Phase 6 → Phase 7 → Phase 8 → Phase 9

PARALLEL WORK:
--------------
- Phase 5 (Data Cleaning) can start after Phase 2
- Phase 6 (Registry) can start after Phase 3
- Phase 7 (Visualizations) can start after Phase 4
- Phase 8 (API/Frontend) can start after Phase 7

================================================================================
                            SUCCESS CRITERIA
================================================================================

PHASE 1-2: Excel Parser & Schema Detection
✓ Can load .xlsx and .csv files
✓ Can detect columns and infer types (>90% accuracy)

PHASE 3: Schema Normalization
✓ Can normalize column names intelligently
✓ >85% accuracy on test data
✓ Confidence scoring working
✓ Pattern learning working

PHASE 4: Cross-File Relationships
✓ Can detect relationships between files
✓ >90% relationship detection accuracy
✓ Can build relationship graph
✓ Can find join paths

PHASE 5-6: Data Cleaning & Registry
✓ Can clean data (missing values, dates, numerics)
✓ Can store and retrieve schemas
✓ Persistent storage working

PHASE 7: Visualizations
✓ Can generate 2D/3D network graphs
✓ Can generate similarity matrices
✓ Can generate cross-file diagrams
✓ Export functionality working

PHASE 8: API & Frontend
✓ Complete API endpoints
✓ Frontend dashboard working
✓ Interactive visualizations in browser

PHASE 9: Testing & Documentation
✓ Comprehensive test coverage
✓ Complete documentation

================================================================================
                            REFERENCE DOCUMENTS
================================================================================

1. NEXT_PHASE_PLAN.md - Overall phase plan
2. FOOLPROOF_SCHEMA_PLAN.md - Intelligent schema normalization (Phase 3)
3. CROSS_FILE_RELATIONSHIPS.md - Cross-file relationships (Phase 4)
4. SCHEMA_VISUALIZATION_PLAN.md - Visualization system (Phase 7)
5. projectPrd.md - Product requirements
6. projectRoadmap.txt - Project roadmap
7. problemStatement.txt - Problem statement

================================================================================
                            NOTES & CONSIDERATIONS
================================================================================

1. Start with Phase 1 (Excel Parser) - Foundation for everything
2. Phase 3 (Schema Normalization) is the most complex - allocate extra time
3. Phase 4 (Relationships) depends on Phase 3 - ensure Phase 3 is solid
4. Phase 7 (Visualizations) can be developed in parallel with Phase 6
5. Test with real MSME Excel files throughout development
6. Keep user feedback loop in mind - system should learn and improve
7. Performance is important - optimize for large files (50k+ rows)
8. Visualizations should be beautiful and interactive - prioritize UX

================================================================================
                            END OF MASTER PLAN
================================================================================

