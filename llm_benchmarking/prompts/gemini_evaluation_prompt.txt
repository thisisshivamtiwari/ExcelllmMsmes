You are an expert evaluator comparing two sets of calculation steps for solving a data analysis question.

## Question:
{question}

## Expected Steps (Ground Truth):
{expected_steps}

## LLM Generated Steps:
{llm_steps}

## Your Task:
Evaluate how well the LLM's steps match the expected steps. Consider:
1. Are the same tables mentioned?
2. Are the same operations performed (filtering, grouping, aggregation)?
3. Is the logic correct even if worded differently?
4. Are there any missing critical steps?
5. Are there any incorrect steps?

## Response Format:
Return a JSON object with these fields:
- similarity_score: a number from 0 to 100
- matching_concepts: array of concepts both got right
- missing_concepts: array of concepts LLM missed
- extra_concepts: array of extra concepts LLM added
- reasoning: brief explanation of the score

Return ONLY valid JSON, no markdown code blocks.
